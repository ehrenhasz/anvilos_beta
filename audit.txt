import json
import re

with open("installed_binaries.json", "r") as f:
    data = json.load(f)

binaries = data["binaries"]

# Sovereignty Protocol / Anvil Doctrine Filters
FORBIDDEN_PATTERNS = {
    "COMPILERS_BUILD": [
        r"^gcc.*", r"^g\+\+.*", r"^make$", r"^cmake$", r"^clang.*", 
        r"^automake", r"^autoconf", r"^as$", r"^ld$", r"^gdb$"
    ],
    "INTERPRETERS": [
        r"^python[0-9.]*$", r"^perl.*", r"^ruby.*", r"^php.*", r"^lua.*", r"^node.*", r"^npm.*"
    ],
    "PACKAGE_MGMT": [
        r"^apt.*", r"^dpkg.*", r"^snap.*", r"^flatpak.*", r"^rpm.*", r"^alien.*"
    ],
    "NETWORK_CLIENTS": [
        r"^curl$", r"^wget$", r"^ftp$", r"^telnet$", r"^netcat$", r"^nc$", 
        r"^ssh$", r"^scp$", r"^rsync$", r"^sftp$"
    ],
    "EDITORS_DOCS": [
        r"^vim.*", r"^nano$", r"^emacs.*", r"^man$", r"^info$", r"^less$", r"^more$"
    ]
}

candidates = {k: [] for k in FORBIDDEN_PATTERNS.keys()}
total_size = 0

for b in binaries:
    name = b["name"]
    path = b["path"]
    size = b["size"]
    
    # Skip Anvil/System Criticals if they happen to match (unlikely for these strict patterns but good practice)
    if name == "python3" and "/usr/bin/python3" in path:
        # Keep system python for now as 'bigiron.py' and system scripts likely depend on it
        # until "Lobotomy" phase.
        continue

    for category, patterns in FORBIDDEN_PATTERNS.items():
        for pat in patterns:
            if re.match(pat, name):
                candidates[category].append(path)
                total_size += size
                break

print(f"ANALYSIS REPORT (Based on Anvil Doctrine)")
print(f"----------------------------------------")
for cat, items in candidates.items():
    print(f"{cat}: {len(items)} binaries")
    if len(items) > 0:
        print(f"  Examples: {', '.join([x.split('/')[-1] for x in items[:5]])}...")

print(f"----------------------------------------")
print(f"Total Candidate Candidates for Removal: {sum(len(l) for l in candidates.values())}")
print(f"Total Size on Disk: {total_size / 1024 / 1024:.2f} MB")

with open("exclusion_candidates.json", "w") as f:
    json.dump(candidates, f, indent=2)
import json
import os
import shutil

# Load the exclusion candidates (the 158 flagged binaries)
try:
    with open("exclusion_candidates.json", "r") as f:
        data = json.load(f)
except FileNotFoundError:
    print("exclusion_candidates.json not found.")
    exit(1)

# Base directory for the folders
BASE_DIR = "oss_sovereignty/legacy_bin"
os.makedirs(BASE_DIR, exist_ok=True)

# Iterate through categories and create folders/cards
count = 0
for category, paths in data.items():
    # Create category folder
    cat_dir = os.path.join(BASE_DIR, category)
    os.makedirs(cat_dir, exist_ok=True)
    
    for path in paths:
        bin_name = os.path.basename(path)
        # Create a folder for the binary
        bin_dir = os.path.join(cat_dir, bin_name)
        os.makedirs(bin_dir, exist_ok=True)
        
        # Create a "card" (metadata file) for it
        card_content = {
            "id": f"legacy_{bin_name}",
            "original_path": path,
            "category": category,
            "status": "flagged_for_removal",
            "replacement_strategy": "rewrite_in_anvil"
        }
        
        with open(os.path.join(bin_dir, "card.json"), "w") as f:
            json.dump(card_content, f, indent=2)
            
        count += 1

print(f"Created {count} folders and cards in {BASE_DIR}")
import json
import os

CARD_PATH = "runtime/card_queue.json"

def purge_legacy_crap():
    if not os.path.exists(CARD_PATH):
        return

    with open(CARD_PATH, "r") as f:
        queue = json.load(f)

    # Keywords to identify "legacy crap" we don't need
    crap_keywords = ["sys_18_64Bit_Cloud", "sys_17_32Bit_Era", "sys_fix_failed_sov_paths"]
    
    initial_count = len(queue)
    # Filter out any card that mentions these paths in the command or ID
    clean_queue = []
    for card in queue:
        card_str = json.dumps(card)
        if any(kw in card_str for kw in crap_keywords):
            print(f">> Purging Card: {card.get('id')} ({card.get('description')})")
            continue
        clean_queue.append(card)

    removed_count = initial_count - len(clean_queue)
    
    with open(CARD_PATH, "w") as f:
        json.dump(clean_queue, f, indent=2)
    
    print(f">> Purged {removed_count} legacy cards. Queue is now clean.")

if __name__ == "__main__":
    purge_legacy_crap()
import json
import os
import subprocess
from datetime import datetime

CARD_PATH = "runtime/card_queue.json"
CARD_ID = "sys_fix_failed_sov_paths"

def add_card():
    # Identify failed cards and their commands
    failed_commands = []
    if os.path.exists(CARD_PATH):
        with open(CARD_PATH, "r") as f:
            data = json.load(f)
            for card in data:
                if card.get("status") == "failed" and "assimilate.py" in card.get("command", ""):
                    # Extract target paths from command to ensure they exist
                    # command example: python3 system/scripts/assimilate.py path url && ...
                    cmd = card["command"]
                    failed_commands.append(cmd)

    if not failed_commands:
        print(">> No failed assimilation cards found.")
        return

    # Construct fix command: mkdir -p for all parent dirs + rerun
    # Actually, let's just make sure the root sovereignty dirs exist
    setup_cmd = "mkdir -p oss_sovereignty/sys_18_64Bit_Cloud/04_Languages_Runtimes oss_sovereignty/sys_18_64Bit_Cloud/03_Virtualization oss_sovereignty/sys_18_64Bit_Cloud/01_Operating_Systems oss_sovereignty/sys_17_32Bit_Era/01_Consoles oss_sovereignty/sys_17_32Bit_Era/02_Computers oss_sovereignty/sys_17_32Bit_Era/03_Toolchains"
    
    card = {
        "id": CARD_ID,
        "description": "FIX: Create missing parent directories for failed sovereignty cards and retry assimilation.",
        "status": "pending",
        "command": setup_cmd,
        "created_at": datetime.utcnow().isoformat() + "Z"
    }
    
    # Prepend fix card
    with open(CARD_PATH, "r") as f:
        queue = json.load(f)
    
    # Reset failed cards to pending so they rerun after fix
    for c in queue:
        if c.get("status") == "failed" and "assimilate.py" in c.get("command", ""):
            c["status"] = "pending"
            c["result"] = "Reset for retry after directory fix."

    queue.insert(0, card)
    
    with open(CARD_PATH, "w") as f:
        json.dump(queue, f, indent=2)
    
    print(f">> Card {CARD_ID} added. Reset failed cards to pending.")

if __name__ == "__main__":
    add_card()
